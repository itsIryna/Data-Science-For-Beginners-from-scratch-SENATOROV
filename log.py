"""Log file shows main items of the lessons learned in the course."""

# Урок 27.02.25
#
#     Изучила:
#     - Базовые команды
#     - Просмотр изменений
#     - Работа с журналом
#     - Отмена изменений
#     - Работа с файлами
#     - Работа с GitHub
#     - Дополнительные команды

# Урок 05.03.2025
#
#     Overview of Linear Regression:
#     - что такое линейная регрессия:
#         - определение и цель
#         - пример использования
#     - types:
#         простая и множественная
#     - основн понятия:
#         - переменние
#         - уравнение
#         - гипотеза
#     - шум
#     - оценка параметров модели:
#         - MSE
#         -градиентн спуск
#     - оценка качества модели
#     - проверка предположений
#     - пере- и недообучение модели
#     - регуляризация
#     - вид обучения
#         -с учителем
#         - без
#     - классификация лин. регрес
#

# Урок 12.03.2025
#
#     Нелинейные модели

# ![alt text](screenshots_lessons_notes/12.03/photo_2025-03-26_22-05-02.jpg)

# ![alt text](screenshots_lessons_notes/12.03/photo_2025-03-26_22-05-06.jpg)

# ![alt text](screenshots_lessons_notes/12.03/photo_2025-03-26_22-05-09.jpg)

# ![alt text](screenshots_lessons_notes/12.03/photo_2025-03-26_22-05-13.jpg)

# ![alt text](screenshots_lessons_notes/12.03/photo_2025-03-26_22-05-17.jpg)

# ![alt text](screenshots_lessons_notes/12.03/photo_2025-03-26_22-05-24.jpg)

# ![alt text](screenshots_lessons_notes/12.03/photo_2025-03-26_22-05-27.jpg)

# Урок 21.03.2025
#
#     Свойства оценок коэф одномерной линейной регрессии

# ![alt text](screenshots_lessons_notes/21.03.25/photo_2025-03-26_22-16-40.jpg)

# ![alt text](screenshots_lessons_notes/21.03.25/photo_2025-03-26_22-16-47.jpg)

# ![alt text](screenshots_lessons_notes/21.03.25/photo_2025-03-26_22-16-50.jpg)

# ![alt text](screenshots_lessons_notes/21.03.25/photo_2025-03-26_22-16-57.jpg)

# 28.03.2025
#
#     Методы нахождения коэф линейной регрессии

# ![alt text](screenshots_lessons_notes/28.03.2025/photo_2025-03-31_15-55-27.jpg)

# ![alt text](screenshots_lessons_notes/28.03.2025/photo_2025-03-31_15-55-31.jpg)

# ![alt text](screenshots_lessons_notes/28.03.2025/photo_2025-03-31_15-55-33.jpg)

# 02.04.2025
#
#     Функция потерь, производная

# ![alt text](screenshots_lessons_notes/28.03.2025/photo_2025-03-31_15-55-35.jpg)

# ![alt text](screenshots_lessons_notes/02.04.25/photo_2025-04-09_12-34-34.jpg)

# ![alt text](screenshots_lessons_notes/02.04.25/photo_2025-04-09_12-34-37.jpg)

# 09.04.25
#
#     Дифферинцирование одной или нескольких переменных

# ![alt text](screenshots_lessons_notes/09.04.2025/photo_2025-04-14_22-04-19.jpg)

# ![alt text](screenshots_lessons_notes/09.04.2025/photo_2025-04-14_22-04-25.jpg)

# ![alt text](screenshots_lessons_notes/09.04.2025/photo_2025-04-14_22-09-48.jpg)

# ![alt text](screenshots_lessons_notes/09.04.2025/photo_2025-04-14_22-04-28.jpg)

# ![alt text](screenshots_lessons_notes/09.04.2025/photo_2025-04-14_22-04-23.jpg)

# ### 16.04 Частные производные
#
# ![alt text](screenshots_lessons_notes/16.04.25/photo_2025-04-24_19-01-22.jpg)

# ### 23.04 Производная по направлению
#
# ![alt text](screenshots_lessons_notes/23.04.25/IMG_4960.jpg)

# ### 07.04 Повторение. Мат.анализ. Градиентный спуск
#

# ![alt text](screenshots_lessons_notes/07.04.25/photo_2025-05-13_12-58-58.jpg)

# ### 14.05 Повторение

# ![alt text](screenshots_lessons_notes/14.05/photo_2025-05-20_15-11-22.jpg)
# ![alt text](screenshots_lessons_notes/14.05/photo_2025-05-20_15-11-30.jpg)

# ![alt text](screenshots_lessons_notes/14.05/photo_2025-05-20_15-11-25.jpg)
# ![alt text](screenshots_lessons_notes/14.05/photo_2025-05-20_15-11-36.jpg)
# ![alt text](screenshots_lessons_notes/14.05/photo_2025-05-20_15-11-28.jpg)
# ![alt text](screenshots_lessons_notes/14.05/photo_2025-05-20_15-11-33.jpg)
# ![alt text](screenshots_lessons_notes/14.05/photo_2025-05-20_15-11-39.jpg)
#

# ### 21.05 Types of data sets
#
# - train data has 75% of data
# - test data has 25%
# - градиентный спуск -это численный метод
# - SSE - sum square error
# - MSE - min sum
# - MSE получаем из SSE
# - SSE число большое и нужно его усреднить
# - матрица признаков, матрица таргетов
# - разные размерности в матрицах

# ### 28.05 Разбор формулы
#
# - чат gpt выдает информацию на основании парсинга данных
# - numpy.shape (метод return a shape of an array, возвращает кортеж чисел (row, column))
# - dimension - размерность
# - data set состоит из матрицы признаков(х) и матрицы откликов(у)
# - w - это скаляр в одномерной регрессии
# - по умолчанию работаем с вектором столбцом
# - [] - 1D, [[]] - 2D
# - одна колонка - это вектор столбец
# - одна строка - это вектор строка
# - квадратная матрица = строки совпадают со столбцами пример: 3х3
#

# ### Review "Essential Math for Data Science" 11.06
# - Regression Is Machine Learning?
# - A Basic Linear Regression
# - Fitting a line through our data
# - Sampling Bias
# - esiduals and Squared Errors

# ### Review "Essential Math for Data Science" 13.06
# - Calculating the residuals for a given line and data
# - Why Not Absolute Values?
# - Closed Form Equation

# ### 18.06 Поиск коэффициентов m, b
# - через раскладование теории рядов
# - через метод Крамера

# ## 27.06 Inverse Matrix techniques
# - using inverse and transposed matrices to fit a linear regression
# - inv function in python means normal equation
# - flatten, vstack
# - add a column with value 1

# ### 04.07 Inverse Matrix techniques, continue
# - finding determinant of matrice
# - finding minors
# - finding Agj
